{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecc3b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matimat/.cache/pypoetry/virtualenvs/ium-long-stay-patterns-kVcCAgnW-py3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2026-01-13 20:16:51.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mium_long_stay_patterns.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/matimat/IUM/ium-long-stay-patterns\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "from ium_long_stay_patterns.src.helpers.create_numerical_dataset import create_numerical_dataset, merge_with_stats\n",
    "from ium_long_stay_patterns.config import ProcessedCSV, SAVED_MODELS_DIR\n",
    "from ium_long_stay_patterns.src.helpers.data_loaders import prepare_and_create_loaders\n",
    "from ium_long_stay_patterns.modeling.train import Trainer\n",
    "from models.binary import BinaryClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54b20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f8dc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1368, 18)\n",
      "Target distribution:\n",
      "target\n",
      "0    994\n",
      "1    374\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_numeric = create_numerical_dataset(ProcessedCSV.LISTINGS.path, strategy=True)\n",
    "df_final = merge_with_stats(df_numeric, with_ids=True)\n",
    "\n",
    "X = df_final.drop(columns=['target', 'id', 'host_id', 'listing_id'])\n",
    "y = df_final['target']\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfb8c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize.\n",
    "    Returns validation AUC score.\n",
    "    \"\"\"\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "\n",
    "    hidden_layers = []\n",
    "    for i in range(n_layers):\n",
    "        hidden_size = trial.suggest_int(f'n_units_l{i}', 16, 128, step=16)\n",
    "        hidden_layers.append(hidden_size)\n",
    "\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "\n",
    "    train_loader, val_loader, _, _ = prepare_and_create_loaders(\n",
    "        X, y, batch_size=batch_size, random_state=42, save_test_data=False, verbose=False\n",
    "    )\n",
    "\n",
    "    data_iter = iter(train_loader)\n",
    "    sample_batch, _ = next(data_iter)\n",
    "    input_dim = sample_batch.shape[1]\n",
    "\n",
    "    model = BinaryClassifier(\n",
    "        input_dim=input_dim,\n",
    "        hidden_layers=hidden_layers,\n",
    "        dropout_rate=dropout_rate\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        epochs=10,\n",
    "        device=device,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, 51):\n",
    "        trainer.model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            metrics = trainer._validate(val_loader)\n",
    "\n",
    "            trial.report(metrics['auc'], epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    final_metrics = trainer._validate(val_loader)\n",
    "\n",
    "    return final_metrics['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2fe684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-13 20:16:53,525] A new study created in memory with name: binary_classifier_tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-13 20:16:59,713] Trial 0 finished with value: 0.9180293501048218 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'n_units_l1': 112, 'n_units_l2': 80, 'dropout_rate': 0.0, 'learning_rate': 0.004325844245358131, 'batch_size': 64, 'weight_decay': 7.7281355662327e-05}. Best is trial 0 with value: 0.9180293501048218.\n",
      "[I 2026-01-13 20:17:01,803] Trial 1 finished with value: 0.8163522012578617 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 64, 'n_units_l2': 16, 'dropout_rate': 0.0, 'learning_rate': 0.0003741309800128861, 'batch_size': 128, 'weight_decay': 7.2795713237901115e-06}. Best is trial 0 with value: 0.9180293501048218.\n",
      "[I 2026-01-13 20:17:05,248] Trial 2 finished with value: 0.810796645702306 and parameters: {'n_layers': 3, 'n_units_l0': 48, 'n_units_l1': 64, 'n_units_l2': 112, 'dropout_rate': 0.5, 'learning_rate': 0.0004429722381496332, 'batch_size': 64, 'weight_decay': 3.1114854344513767e-06}. Best is trial 0 with value: 0.9180293501048218.\n",
      "[I 2026-01-13 20:17:09,004] Trial 3 finished with value: 0.8061844863731656 and parameters: {'n_layers': 2, 'n_units_l0': 112, 'n_units_l1': 48, 'dropout_rate': 0.5, 'learning_rate': 0.000364829002149759, 'batch_size': 64, 'weight_decay': 6.495698065506054e-05}. Best is trial 0 with value: 0.9180293501048218.\n",
      "[I 2026-01-13 20:17:15,104] Trial 4 finished with value: 0.9179245283018869 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0032828113909184643, 'batch_size': 32, 'weight_decay': 3.5072229101950365e-06}. Best is trial 0 with value: 0.9180293501048218.\n",
      "[I 2026-01-13 20:17:16,572] Trial 5 pruned. \n",
      "[I 2026-01-13 20:17:22,914] Trial 6 finished with value: 0.9084905660377358 and parameters: {'n_layers': 2, 'n_units_l0': 48, 'n_units_l1': 96, 'dropout_rate': 0.1, 'learning_rate': 0.0015284132332553772, 'batch_size': 32, 'weight_decay': 0.00016456823171706817}. Best is trial 0 with value: 0.9180293501048218.\n",
      "[I 2026-01-13 20:17:24,069] Trial 7 pruned. \n",
      "[I 2026-01-13 20:17:24,491] Trial 8 pruned. \n",
      "[I 2026-01-13 20:17:27,031] Trial 9 finished with value: 0.8808176100628932 and parameters: {'n_layers': 1, 'n_units_l0': 32, 'dropout_rate': 0.1, 'learning_rate': 0.003064956325799556, 'batch_size': 64, 'weight_decay': 0.0003650105917378771}. Best is trial 0 with value: 0.9180293501048218.\n",
      "[I 2026-01-13 20:17:30,435] Trial 10 finished with value: 0.9426624737945495 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 128, 'n_units_l2': 64, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.009012749004923921, 'batch_size': 64, 'weight_decay': 0.0007908623523106931}. Best is trial 10 with value: 0.9426624737945495.\n",
      "[I 2026-01-13 20:17:33,995] Trial 11 finished with value: 0.9535639412997904 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 128, 'n_units_l2': 64, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.008375350811026756, 'batch_size': 64, 'weight_decay': 0.0007186556345221058}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:17:37,537] Trial 12 finished with value: 0.9528301886792454 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 16, 'n_units_l2': 48, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.00977514570995567, 'batch_size': 64, 'weight_decay': 0.0008735734953231181}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:17:38,280] Trial 13 pruned. \n",
      "[I 2026-01-13 20:17:38,987] Trial 14 pruned. \n",
      "[I 2026-01-13 20:17:39,616] Trial 15 pruned. \n",
      "[I 2026-01-13 20:17:40,029] Trial 16 pruned. \n",
      "[I 2026-01-13 20:17:40,671] Trial 17 pruned. \n",
      "[I 2026-01-13 20:17:41,195] Trial 18 pruned. \n",
      "[I 2026-01-13 20:17:41,618] Trial 19 pruned. \n",
      "[I 2026-01-13 20:17:44,559] Trial 20 finished with value: 0.9163522012578617 and parameters: {'n_layers': 2, 'n_units_l0': 128, 'n_units_l1': 32, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.003998396496849228, 'batch_size': 64, 'weight_decay': 0.00016570017937446194}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:17:47,943] Trial 21 finished with value: 0.9457023060796647 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 128, 'n_units_l2': 64, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.008662370617424949, 'batch_size': 64, 'weight_decay': 0.0008827723189969847}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:17:51,313] Trial 22 finished with value: 0.9308176100628931 and parameters: {'n_layers': 3, 'n_units_l0': 64, 'n_units_l1': 128, 'n_units_l2': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0094881287083175, 'batch_size': 64, 'weight_decay': 0.0009242421203773544}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:17:54,697] Trial 23 finished with value: 0.9420335429769392 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 96, 'n_units_l2': 96, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.005981743823075902, 'batch_size': 64, 'weight_decay': 0.00043015660226442833}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:17:55,388] Trial 24 pruned. \n",
      "[I 2026-01-13 20:17:56,112] Trial 25 pruned. \n",
      "[I 2026-01-13 20:17:56,846] Trial 26 pruned. \n",
      "[I 2026-01-13 20:17:59,801] Trial 27 finished with value: 0.9450733752620546 and parameters: {'n_layers': 2, 'n_units_l0': 80, 'n_units_l1': 48, 'dropout_rate': 0.2, 'learning_rate': 0.0044939131959613205, 'batch_size': 64, 'weight_decay': 0.0006385530529917387}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:18:06,049] Trial 28 finished with value: 0.9174004192872118 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'n_units_l1': 96, 'n_units_l2': 96, 'dropout_rate': 0.4, 'learning_rate': 0.007633941540587887, 'batch_size': 32, 'weight_decay': 4.333667026639418e-05}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:18:06,464] Trial 29 pruned. \n",
      "[I 2026-01-13 20:18:07,165] Trial 30 pruned. \n",
      "[I 2026-01-13 20:18:07,784] Trial 31 pruned. \n",
      "[I 2026-01-13 20:18:08,384] Trial 32 pruned. \n",
      "[I 2026-01-13 20:18:08,930] Trial 33 pruned. \n",
      "[I 2026-01-13 20:18:09,538] Trial 34 pruned. \n",
      "[I 2026-01-13 20:18:12,053] Trial 35 finished with value: 0.9363731656184486 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.009931105989525898, 'batch_size': 64, 'weight_decay': 0.0006114654739923335}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:18:12,794] Trial 36 pruned. \n",
      "[I 2026-01-13 20:18:14,087] Trial 37 pruned. \n",
      "[I 2026-01-13 20:18:14,422] Trial 38 pruned. \n",
      "[I 2026-01-13 20:18:15,023] Trial 39 pruned. \n",
      "[I 2026-01-13 20:18:16,802] Trial 40 pruned. \n",
      "[I 2026-01-13 20:18:17,533] Trial 41 pruned. \n",
      "[I 2026-01-13 20:18:20,861] Trial 42 finished with value: 0.9254716981132077 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'n_units_l1': 128, 'n_units_l2': 64, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.008098359529926036, 'batch_size': 64, 'weight_decay': 0.0008205464357783328}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:18:24,241] Trial 43 finished with value: 0.950104821802935 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 112, 'n_units_l2': 48, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.00936504382871239, 'batch_size': 64, 'weight_decay': 0.00047851083788780615}. Best is trial 11 with value: 0.9535639412997904.\n",
      "[I 2026-01-13 20:18:24,955] Trial 44 pruned. \n",
      "[I 2026-01-13 20:18:25,649] Trial 45 pruned. \n",
      "[I 2026-01-13 20:18:29,111] Trial 46 pruned. \n",
      "[I 2026-01-13 20:18:29,756] Trial 47 pruned. \n",
      "[I 2026-01-13 20:18:31,086] Trial 48 pruned. \n",
      "[I 2026-01-13 20:18:31,504] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization complete!\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10),\n",
    "    study_name='binary_classifier_tuning'\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "study.optimize(objective, n_trials=50, timeout=3600)\n",
    "\n",
    "print(\"\\nOptimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf60e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (AUC): 0.9536\n",
      "\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 80\n",
      "    n_units_l1: 128\n",
      "    n_units_l2: 64\n",
      "    dropout_rate: 0.30000000000000004\n",
      "    learning_rate: 0.008375350811026756\n",
      "    batch_size: 64\n",
      "    weight_decay: 0.0007186556345221058\n"
     ]
    }
   ],
   "source": [
    "# Best trial\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value (AUC): {trial.value:.4f}\")\n",
    "print(\"\\n  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26ae85",
   "metadata": {},
   "source": [
    "## Top 10 best trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a68118a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_dropout_rate</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_layers</th>\n",
       "      <th>params_n_units_l0</th>\n",
       "      <th>params_n_units_l1</th>\n",
       "      <th>params_n_units_l2</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.953564</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.000874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.950105</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>112.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.945702</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.945073</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.942662</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.942034</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.936373</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.925472</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value  params_batch_size  params_dropout_rate  \\\n",
       "11      11  0.953564                 64                  0.3   \n",
       "12      12  0.952830                 64                  0.3   \n",
       "43      43  0.950105                 64                  0.3   \n",
       "21      21  0.945702                 64                  0.3   \n",
       "27      27  0.945073                 64                  0.2   \n",
       "10      10  0.942662                 64                  0.3   \n",
       "23      23  0.942034                 64                  0.3   \n",
       "35      35  0.936373                 64                  0.3   \n",
       "22      22  0.930818                 64                  0.4   \n",
       "42      42  0.925472                 64                  0.3   \n",
       "\n",
       "    params_learning_rate  params_n_layers  params_n_units_l0  \\\n",
       "11              0.008375                3                 80   \n",
       "12              0.009775                3                 80   \n",
       "43              0.009365                3                 80   \n",
       "21              0.008662                3                 80   \n",
       "27              0.004494                2                 80   \n",
       "10              0.009013                3                 80   \n",
       "23              0.005982                3                 80   \n",
       "35              0.009931                1                112   \n",
       "22              0.009488                3                 64   \n",
       "42              0.008098                3                 96   \n",
       "\n",
       "    params_n_units_l1  params_n_units_l2  params_weight_decay  \n",
       "11              128.0               64.0             0.000719  \n",
       "12               16.0               48.0             0.000874  \n",
       "43              112.0               48.0             0.000479  \n",
       "21              128.0               64.0             0.000883  \n",
       "27               48.0                NaN             0.000639  \n",
       "10              128.0               64.0             0.000791  \n",
       "23               96.0               96.0             0.000430  \n",
       "35                NaN                NaN             0.000611  \n",
       "22              128.0               64.0             0.000924  \n",
       "42              128.0               64.0             0.000821  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = study.trials_dataframe()\n",
    "\n",
    "df_sorted = df.sort_values(\"value\", ascending=False)\n",
    "\n",
    "top10 = df_sorted.head(10)\n",
    "\n",
    "cols = [\"number\", \"value\"] + [c for c in df_sorted.columns if c.startswith(\"params_\")]\n",
    "\n",
    "display(top10[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aed6b2",
   "metadata": {},
   "source": [
    "Params saved in *config.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec5859",
   "metadata": {},
   "source": [
    "# Train best model - in *classification_numeric_data.ipynb*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ium-long-stay-patterns-kVcCAgnW-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
